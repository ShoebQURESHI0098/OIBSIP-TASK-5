# OIBSIP-TASK-5
OIBSIP tech internship Sales Prediction using Python
# ğŸ“Š Sales Prediction using Python & Machine Learning

## ğŸ“– Overview
This project predicts future sales based on historical data using various machine learning models. The dataset includes features like date, store, product, and past sales to generate accurate forecasts.

## ğŸ“Š Dataset
The dataset contains the following features:
- ğŸª **Store ID** (Unique identifier for each store)  
- ğŸ› **Product ID** (Unique identifier for each product)  
- ğŸ“… **Date** (Daily/Monthly sales data)  
- ğŸ’° **Sales (Target Variable)** (Total sales for a given period)  
- ğŸ¯ **Promotions, Discounts, Seasonality Effects** (Optional)  

## ğŸš€ Technologies Used
- ğŸ Python  
- ğŸ“Š Pandas, NumPy  
- ğŸ“ˆ Matplotlib, Seaborn  
- ğŸ¤– Scikit-learn (Machine Learning)  
- â³ Statsmodels (Time Series Analysis)  
- ğŸ”¢ Jupyter Notebook  

## ğŸ—ï¸ Machine Learning Models Used
- âœ… Linear Regression  
- âœ… Decision Tree Regressor  
- âœ… Random Forest Regressor  
- âœ… XGBoost Regressor  
- âœ… ARIMA (For time-series forecasting)  
- âœ… LSTM (Deep Learning for advanced forecasting)  

## ğŸ“Œ Project Workflow
1. **Data Preprocessing:** Handle missing values, feature engineering, and scaling.  
2. **Exploratory Data Analysis (EDA):** Identify trends, seasonality, and correlations.  
3. **Feature Engineering:** Convert categorical variables, create new time-based features.  
4. **Model Training & Evaluation:** Train multiple models and compare performance using RMSE and RÂ² scores.  
5. **Forecasting & Visualization:** Generate future sales predictions and plot insights.  

## ğŸ› ï¸ Installation & Setup
To run this project locally:

```sh
# Clone this repository
git clone https://github.com/yourusername/sales-prediction.git
cd sales-prediction

# Install dependencies
pip install -r requirements.txt

# Run the Jupyter Notebook
jupyter notebook
ğŸ“Š Model Performance
Model	RMSE (Lower is Better)	RÂ² Score (Higher is Better)
Linear Regression	3000	85%
Decision Tree	2500	88%
Random Forest	2000	92%
XGBoost	1800	94%
ARIMA	2200	90%
LSTM	1500	96%
